{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be02a957-7133-4d02-818e-fedeb3cecb05",
   "metadata": {},
   "source": [
    "# Project 02 -- Anthony Micco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1228853-dd19-4ab2-89e0-0394d7d72de3",
   "metadata": {},
   "source": [
    "**TA Help:** N/A\n",
    "\n",
    "**Collaboration:** N/A\n",
    "\n",
    "**Internet Resources:** Used Pandas documentation to understand how to slice rows and columns for example in question 1 (https://pandas.pydata.org/docs/user_guide/indexing.html) \\\n",
    "Again used Pandas documentation to figure out how to make sure the plot labels were not rotated (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html) \\\n",
    "Watched a video to better understand the difference between convolution and cross correlation (https://www.youtube.com/watch?v=tS-ib_mgGbU) \\\n",
    "Read through this GeeksForGeeks article to better understand max pooling and average pooling (https://www.geeksforgeeks.org/deep-learning/cnn-introduction-to-pooling-layer/) \\\n",
    "Used another GeeksForGeeks article to help in my understanding of fully connected layers and convolutional layers (https://www.geeksforgeeks.org/deep-learning/fully-connected-layer-vs-convolutional-layer/) \\\n",
    "Reviewed a GeekForGeeks article on Epochs to understand why we use them as well as their advantages and disadvantages (https://www.geeksforgeeks.org/machine-learning/epoch-in-machine-learning/) \\\n",
    "Utilized article to assist in my explanation of the forward and backward pass (https://towardsdatascience.com/neural-networks-forward-pass-and-backpropagation-be3b75a1cfcc/) \\\n",
    "Used to understand what the loss.backward() function did (https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944) \\\n",
    "Read to understand what the optimizer.step() function did within the model (https://medium.com/@whyamit404/what-does-optimizer-step-do-in-pytorch-83f0fb0cbfe5)\n",
    "\n",
    "**ChatGPT, Gemini, Claude, etc:** N/A\n",
    "\n",
    "**Link to AI Chat History**: None\n",
    "\n",
    "**OVERALL MESSAGE:** Any time that you used anything except your brain to solve the questions in these projects, you need to disclose such resources at the start of the project, with details about your usage of the tools.\n",
    "\n",
    "**YOUR OWN WORK:** Even when you utilize other resources, do NOT just copy and paste.  Write all explanations in your own words, using several sentences in English, which are understandable and which you wrote (and did not just copy and paste)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180e742-8e39-4698-98ff-5b00c8cf8ea0",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49445606-d363-41b4-b479-e319a9a84c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in the MNIST training data\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/anvil/projects/tdm/data/mnist/mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c380bd5-2b38-466e-8975-8830e98dd855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the head of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be3e09e3-0311-42b3-9a13-e064961db29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a362ff3b-4089-49a3-97c3-65519ae91643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>1x10</th>\n",
       "      <th>...</th>\n",
       "      <th>1x20</th>\n",
       "      <th>1x21</th>\n",
       "      <th>1x22</th>\n",
       "      <th>1x23</th>\n",
       "      <th>1x24</th>\n",
       "      <th>1x25</th>\n",
       "      <th>1x26</th>\n",
       "      <th>1x27</th>\n",
       "      <th>1x28</th>\n",
       "      <th>2x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  1x20  1x21  1x22  \\\n",
       "0    0    0    0    0    0    0    0    0    0     0  ...     0     0     0   \n",
       "1    0    0    0    0    0    0    0    0    0     0  ...     0     0     0   \n",
       "2    0    0    0    0    0    0    0    0    0     0  ...     0     0     0   \n",
       "3    0    0    0    0    0    0    0    0    0     0  ...     0     0     0   \n",
       "4    0    0    0    0    0    0    0    0    0     0  ...     0     0     0   \n",
       "\n",
       "   1x23  1x24  1x25  1x26  1x27  1x28  2x1  \n",
       "0     0     0     0     0     0     0    0  \n",
       "1     0     0     0     0     0     0    0  \n",
       "2     0     0     0     0     0     0    0  \n",
       "3     0     0     0     0     0     0    0  \n",
       "4     0     0     0     0     0     0    0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the first 30 columns of the first 5 rows\n",
    "data.iloc[:5, 1:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456e57c-4a12-464b-999a-ef2df5af80c1",
   "metadata": {},
   "source": [
    "1a) At first glance, I notice there are a lot of 0's in the dataset. This is obviously because the number in each picture is the only thing in white, so there are a lot more black pixels than lighter colored or white pixels. The vastness of the dataset is also really eyepopping to me because it is not very often that we work with datasets as large as this one with over 750 columns. I also think its really unique how one row of data with 785 total columns containing the numbers 0 to 255 can represent an image. It is a simple image, but it makes me think about how we could do this with more complex images if we were able to calculate the pixel color at certain locations. \n",
    "1b) In this dataset, each row represents one complete image with 784 pixels, while each column represents a single pixel of the image where each value in the column represents how light or dark the pixel is based on a value from 0 to 255. For example, the first column, 1x1 represents the pixel in the first column and first row of the image which contains the value 0, meaning it is black. It then increments until it gets to the 1x28 column which is the last column of the first row of the image before the second row of the image starts with column 2x1. This increment repeats until we get to the very last column which is 28x28 with a value of 0 and a complete image.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc601975-35ed-4680-a4e1-0273ee3cc047",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a16336a1-1ef0-41e8-bc7c-49387db27497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in imports\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd45bc5f-4d4d-4306-a35d-22dca294f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the MNIST data loader class\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # First column of a row idx is the label\n",
    "        label = self.data.iloc[idx, 0]\n",
    "        # Get all remainder of the row (columns - pixels) and returns 1D array through .values\n",
    "        # 8bit unsigned integers allow visual display of grayscale images. It has 0-255 for the 256 different intensity levels\n",
    "        pixels = self.data.iloc[idx, 1:].values.astype(np.uint8)\n",
    "        # Convert into 2D array (28x28)\n",
    "        image = pixels.reshape(28, 28)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7c77cf2-f95f-4fb5-a1b1-4217e719e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in the test and training data using the class\n",
    "transform = transforms.Compose([transforms.ToTensor(),   # converts image to tensor [0,1]\n",
    "                                 transforms.Normalize((0.5,), (0.5,))])  # normalize to [-1,1]\n",
    "\n",
    "#loading in training data\n",
    "train_dataset = MNISTDataset('/anvil/projects/tdm/data/mnist/mnist_train.csv', transform=transform)\n",
    "load_train = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "#loading in testing data\n",
    "test_dataset = MNISTDataset('/anvil/projects/tdm/data/mnist/mnist_test.csv', transform=transform)\n",
    "load_test = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "004bc131-adaf-4cba-8895-8e7b66fd6acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size: 60000\n",
      "Testing Dataset Size: 10000\n"
     ]
    }
   ],
   "source": [
    "#printing the sizes of the datasets\n",
    "print(f\"Training Dataset Size: {train_dataset.__len__()}\\nTesting Dataset Size: {test_dataset.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04e92921-df30-4b5c-a247-b95b9ea853e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = []\n",
    "\n",
    "#iterate through each sample in train_dataset\n",
    "#obtain the label  (digits 0-9) and add to the list\n",
    "for image,label in train_dataset:\n",
    "    labels.append(label)\n",
    "\n",
    "#converting labels list to pandas series and sorting the occurences by the labels (0-9)\n",
    "label_series = pd.Series(labels).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ad21c26-84fe-4022-b2cf-6708e0dbb461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5923\n",
       "1    6742\n",
       "2    5958\n",
       "3    6131\n",
       "4    5842\n",
       "5    5421\n",
       "6    5918\n",
       "7    6265\n",
       "8    5851\n",
       "9    5949\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examining the output of label_series\n",
    "label_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8263f746-442f-43f7-9e51-8882dc270ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Labels', ylabel='Occurrences'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the series using pandas plot function\n",
    "label_series.plot(xlabel=\"Labels\", ylabel=\"Occurrences\", kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b586ad1-b18b-4d8d-ae01-399ce255d6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining the 5 figures we want to see in a single row\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "  image, label = train_dataset[i]\n",
    "  pic = image.squeeze().numpy()\n",
    "  axes[i].imshow(pic, cmap='gray')\n",
    "  axes[i].set_title(f\"Label: {label}\")\n",
    "  axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc22d4-ddc3-41cc-a91a-cb0025bc0c80",
   "metadata": {},
   "source": [
    "2c) The graph of the distribution of the digits shows us that the distribution of the digits in the data is quite even. This is good because we will not have to worry about providing our model with data that has an uneven distribution of data and hopefully train the model more accurately. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e586edd-ff26-4ce2-8f6b-2424b26f2929",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbe0f40d-9655-4653-9ca8-886bdb61cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for CNN model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e89e051-210c-4f1a-aa01-f30c8cf57c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the cnn model class\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #1st convutional layer\n",
    "        self.conv1 = nn.Conv2d(1,8,kernel_size=3, stride=1,padding=1)\n",
    "\n",
    "        #2nd convutional layer\n",
    "        self.conv2 = nn.Conv2d(8,16,kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #1st convolutional layer with ReLU and max pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "\n",
    "        #2nd convolutional layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x,7,7)\n",
    "        \n",
    "        #flatten\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "\n",
    "        #fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6229f-35f7-400c-8366-c442baa5cf47",
   "metadata": {},
   "source": [
    "**3c)** The difference between convolution and cross correlation is that convolution reverses the rows and columns of the image filter before completing the multiplication and summation, while cross correlation keeps the filter the same. For example, if the filter was a 3x3 grid, index 1 would be in the top left in cross correlation and increment by one left to right, while in convolution, index 1 would be in the bottom right and increment by one right to left. While they are different, CNN works with both because both methods produce the same or similar outputs, and if they do not, the difference is not significant because the training process allows the model to learn the kernal weights. \\\n",
    "**3d)** Max pooling is a method that finds the maximum element from the regions of the feature map covered by the filter. It slides over a feature map and reviews each section and retrieves the max value from each region to create a new feature map that has a reduced spatial size. Average pooling is a method that finds the average value from the sum of the elements in each individual region of the feature map covered by the filter. It slides over the feature map and reviews each section, sums up the elements in the region and then divides it by the total number of elements in that region to find the average, which it then stores. This also is used to reduce the spatial size of a feature map. The difference between the two is that max pooling provides the most prominent feature in each region of the feature map, while average pooling provides an average of all the features in a feature map. When you want to find something prominent in an image, max pooling is more efficient because it will retrieve the element with the highest intensity of pixels, while average pooling is useful when it is important to maintain an overall context of the image and not just a specific feature. \\\n",
    "**3e)** The difference between the convolutional layer and the fully connected layer is that the convolutional layer is used to learn and extract features using kernals and feature maps, while the fully connected layer is used to classify the features found by the convolutional layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da22f29c-d245-4d2b-9fc1-ca14cb6087d9",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cffc767-d1c8-4d64-b7dc-f0d2ee8a80d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model paramters such as the loss function and optimizer\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = cnn().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35b7723d-78ab-4507-b818-cc53a728be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 938/938 [00:16<00:00, 55.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 938/938 [00:16<00:00, 56.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 938/938 [00:16<00:00, 56.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 938/938 [00:16<00:00, 56.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 938/938 [00:16<00:00, 56.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#running the model on training data\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # adding progress bar\n",
    "    for images, labels in tqdm(load_train, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(load_train)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d552245-b4d6-474a-9cc9-fa7b8e674d55",
   "metadata": {},
   "source": [
    "**4b)** The purpose of running multiple epochs is to ensure the model has enough time to be trained on the data and allow the model to refine its parameters to improve its learning. Each time we run an epoch, the model processes the entire set of data, so by running it more than once, it will better learn the data and in theory have a higher accuracy. If we ran too few epochs, then the model might not be as accurate compared to if we ran it with more. However, it is important we do not run too much epochs because then it will take a lot longer to train the model and it is also more computationally expensive so it will require a more powerful computer. \\\n",
    "**4c)** The forward pass is the passing of information from one node to the next. It takes the input, x, and feeds it to the first layer of n nodes, applies an activation function and any weights and biases to each node in the first layer. Then it proceeds to take the output of each node and feed them to the next layer of n nodes and again applies an activation and any weights and biases. It repeats this until it reaches an output that takes in the previous layer's n nodes as input before finally calculating the loss which essentially tells us the accuracy of the model. A backward pass is the process of walking backward through the neural network to calculate how changes in the loss function's parameters can impact the loss value. This method begins at the output node, and walks backward through the network and takes the derivative of the output with respect to each of the nodes' weights and biases. It performs these calculations on each of these nodes until it reaches the input node where it generates a gradient of all the weights and biases so the model can update itself. The difference between these two processes is that the forward pass calculates how many errors a model made in an iteration, while a backward pass determines how the weights and biases can be adjusted to make the model more accurate and decrease loss.    \n",
    "**4d)** The loss.backward() function calculates the derivative of the output with respect to each node's weights and biases and actually performs the backward propogation of the model, while optimizer.step() aims to optimize the model's parameters in order to minimize the loss function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9cdac-3e92-498f-83fa-e089bfc44ac8",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d370d7c9-06db-42b9-b75f-240481a5c491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.54"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the accuracy of the model using max pooling \n",
    "def calculate_accuracy(model, data_loader, device):\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize counters\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate through all batches\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # torch.max will return (max, max index). We are getting the predicted index.\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Get percent accuracy\n",
    "    return 100*correct/total\n",
    "\n",
    "calculate_accuracy(model, load_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1afbd1e-d1a0-408e-8aff-1c24ef4614ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying model to use average pooling\n",
    "#defining the cnn model class\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #1st convutional layer\n",
    "        self.conv1 = nn.Conv2d(1,8,kernel_size=3, stride=1,padding=1)\n",
    "\n",
    "        #2nd convutional layer\n",
    "        self.conv2 = nn.Conv2d(8,16,kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #1st convolutional layer with ReLU and max pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.avg_pool2d(x,2,2)\n",
    "\n",
    "        #2nd convolutional layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.avg_pool2d(x,7,7)\n",
    "        \n",
    "        #flatten\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "\n",
    "        #fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4a28f34-397e-48e3-801f-b36eed7c6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining parameters for updated model\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = cnn().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "557b2c04-bea1-4e8a-a342-d2d3b9cf8907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 938/938 [00:17<00:00, 54.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 938/938 [00:16<00:00, 55.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 938/938 [00:16<00:00, 55.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 938/938 [00:16<00:00, 56.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.2497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 938/938 [00:16<00:00, 55.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#running the model on training data\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # adding progress bar\n",
    "    for images, labels in tqdm(load_train, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(load_train)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "030cdb41-7907-40d6-9d66-fa99e7432b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.24"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the accuracy of the model using max pooling \n",
    "def calculate_accuracy(model, data_loader, device):\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize counters\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate through all batches\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # torch.max will return (max, max index). We are getting the predicted index.\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Get percent accuracy\n",
    "    return 100*correct/total\n",
    "\n",
    "calculate_accuracy(model, load_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf00fb-2418-460f-ae94-2a32b0c28952",
   "metadata": {},
   "source": [
    "Markdown notes and full English sentences and analysis written here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76442d6-d02e-4f26-b9d6-c3183e1d6929",
   "metadata": {},
   "source": [
    "## Pledge\n",
    "\n",
    "By submitting this work I hereby pledge that this is my own, personal work. I've acknowledged in the designated place at the top of this file all sources that I used to complete said work, including but not limited to: online resources, books, and electronic communications. I've noted all collaboration with fellow students and/or TA's. I did not copy or plagiarize another's work.\n",
    "\n",
    "> As a Boilermaker pursuing academic excellence, I pledge to be honest and true in all that I do. Accountable together – We are Purdue.\n",
    "\n",
    "https://www.purdue.edu/odos/osrr/honor-pledge/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
